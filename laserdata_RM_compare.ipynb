{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c9af93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.svm import SVR\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.spatial.distance import pdist, cdist, squareform\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics.pairwise import laplacian_kernel,chi2_kernel\n",
    "###############################################################################\n",
    "# Fit regression model\n",
    "#svr1 = SVR(kernel='rbf', C=100, gamma=0.1)\n",
    "#svr1=SVR()\n",
    "#svr2 = SVR(kernel=mymahal, C=100, gamma='auto')\n",
    "#svr3 = SVR(kernel=myminkowski, C=100)\n",
    "###############################################################################\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35e3e7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rpdd(obs,pred):\n",
    "    rmsep=mean_squared_error(pred,obs,squared=False)\n",
    "\n",
    "    # ratio of performance to deviation\n",
    "    rpd=np.std(obs) / rmsep\n",
    "    return rpd\n",
    "\n",
    "def nrmse(obs, rmse):\n",
    "    NRMSE=rmse/(np.max(obs)-np.min(obs))\n",
    "    return NRMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#filepath=\"G:\\\\E-backup\\\\study\\\\study\\\\2023\\\\hefeng\\\\dataprocess\\\\data2.xls\"\n",
    "filepath=\"data2.xls\"\n",
    "df_laser_tar=pd.read_excel(open(filepath, 'rb'), sheet_name='在线激光打孔参数与焦油量测定结果表')\n",
    "\n",
    "tratio=(df_laser_tar['焦油量(不打孔)']-df_laser_tar['焦油量'])/df_laser_tar['焦油量(不打孔)']\n",
    "z=tratio.dropna()\n",
    "#scaler=StandardScaler()\n",
    "#scaler2=StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "oldz=z\n",
    "\n",
    "scaler2=MinMaxScaler()\n",
    "scaler=StandardScaler()\n",
    "XX = np.column_stack((df_laser_tar['孔数/排'], df_laser_tar['时间']))\n",
    "yy = np.array(z)\n",
    "X = scaler.fit_transform(XX)\n",
    "y = scaler.fit_transform(yy.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.gaussian_process.kernels import StationaryKernelMixin,NormalizedKernelMixin,Kernel,Hyperparameter\n",
    "from sklearn.base import clone\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from sklearn.metrics.pairwise import pairwise_kernels\n",
    "from sklearn.utils.validation import _num_samples\n",
    "\n",
    "class RationalQuadratic_minkow_g(StationaryKernelMixin, NormalizedKernelMixin, Kernel):\n",
    "    \"\"\"Rational Quadratic kernel.\n",
    "\n",
    "    The RationalQuadratic kernel can be seen as a scale mixture (an infinite\n",
    "    sum) of RBF kernels with different characteristic length scales. It is\n",
    "    parameterized by a length scale parameter :math:`l>0` and a scale\n",
    "    mixture parameter :math:`\\\\alpha>0`. Only the isotropic variant\n",
    "    where length_scale :math:`l` is a scalar is supported at the moment.\n",
    "    The kernel is given by:\n",
    "\n",
    "    .. math::\n",
    "        k(x_i, x_j) = \\\\left(\n",
    "        1 + \\\\frac{d(x_i, x_j)^2 }{ 2\\\\alpha  l^2}\\\\right)^{-\\\\alpha}\n",
    "\n",
    "    where :math:`\\\\alpha` is the scale mixture parameter, :math:`l` is\n",
    "    the length scale of the kernel and :math:`d(\\\\cdot,\\\\cdot)` is the\n",
    "    Euclidean distance.\n",
    "    For advice on how to set the parameters, see e.g. [1]_.\n",
    "\n",
    "    Read more in the :ref:`User Guide <gp_kernels>`.\n",
    "\n",
    "    .. versionadded:: 0.18\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    length_scale : float > 0, default=1.0\n",
    "        The length scale of the kernel.\n",
    "\n",
    "    alpha : float > 0, default=1.0\n",
    "        Scale mixture parameter\n",
    "\n",
    "    length_scale_bounds : pair of floats >= 0 or \"fixed\", default=(1e-5, 1e5)\n",
    "        The lower and upper bound on 'length_scale'.\n",
    "        If set to \"fixed\", 'length_scale' cannot be changed during\n",
    "        hyperparameter tuning.\n",
    "\n",
    "    alpha_bounds : pair of floats >= 0 or \"fixed\", default=(1e-5, 1e5)\n",
    "        The lower and upper bound on 'alpha'.\n",
    "        If set to \"fixed\", 'alpha' cannot be changed during\n",
    "        hyperparameter tuning.\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    .. [1] `David Duvenaud (2014). \"The Kernel Cookbook:\n",
    "        Advice on Covariance functions\".\n",
    "        <https://www.cs.toronto.edu/~duvenaud/cookbook/>`_\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> from sklearn.datasets import load_iris\n",
    "    >>> from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "    >>> from sklearn.gaussian_process.kernels import RationalQuadratic\n",
    "    >>> X, y = load_iris(return_X_y=True)\n",
    "    >>> kernel = RationalQuadratic(length_scale=1.0, alpha=1.5)\n",
    "    >>> gpc = GaussianProcessClassifier(kernel=kernel,\n",
    "    ...         random_state=0).fit(X, y)\n",
    "    >>> gpc.score(X, y)\n",
    "    0.9733...\n",
    "    >>> gpc.predict_proba(X[:2,:])\n",
    "    array([[0.8881..., 0.0566..., 0.05518...],\n",
    "            [0.8678..., 0.0707... , 0.0614...]])\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        length_scale=1.0,\n",
    "        alpha=2.0,\n",
    "        length_scale_bounds=(1e-5, 1e5),\n",
    "        alpha_bounds=(1e-5, 1e5),\n",
    "    ):\n",
    "        self.length_scale = length_scale\n",
    "        self.alpha = alpha\n",
    "        self.length_scale_bounds = length_scale_bounds\n",
    "        self.alpha_bounds = alpha_bounds\n",
    "\n",
    "    @property\n",
    "    def hyperparameter_length_scale(self):\n",
    "        return Hyperparameter(\"length_scale\", \"numeric\", self.length_scale_bounds)\n",
    "\n",
    "    @property\n",
    "    def hyperparameter_alpha(self):\n",
    "        return Hyperparameter(\"alpha\", \"numeric\", self.alpha_bounds)\n",
    "\n",
    " \n",
    "    def __call__(self, X, Y=None, eval_gradient=False):\n",
    "        \"\"\"Return the kernel k(X, Y) and optionally its gradient.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : ndarray of shape (n_samples_X, n_features)\n",
    "            Left argument of the returned kernel k(X, Y)\n",
    "\n",
    "        Y : ndarray of shape (n_samples_Y, n_features), default=None\n",
    "            Right argument of the returned kernel k(X, Y). If None, k(X, X)\n",
    "            if evaluated instead.\n",
    "\n",
    "        eval_gradient : bool, default=False\n",
    "            Determines whether the gradient with respect to the log of\n",
    "            the kernel hyperparameter is computed.\n",
    "            Only supported when Y is None.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        K : ndarray of shape (n_samples_X, n_samples_Y)\n",
    "            Kernel k(X, Y)\n",
    "\n",
    "        K_gradient : ndarray of shape (n_samples_X, n_samples_X, n_dims)\n",
    "            The gradient of the kernel k(X, X) with respect to the log of the\n",
    "            hyperparameter of the kernel. Only returned when eval_gradient\n",
    "            is True.\n",
    "        \"\"\"\n",
    "        if len(np.atleast_1d(self.length_scale)) > 1:\n",
    "            raise AttributeError(\n",
    "                \"RationalQuadratic kernel only supports isotropic version, \"\n",
    "                \"please use a single scalar for length_scale\"\n",
    "            )\n",
    "        X = np.atleast_2d(X)\n",
    "        if Y is None:\n",
    "            dists = squareform(pdist(X, metric=\"minkowski\",p=5))\n",
    "            tmp = dists / (2 * self.alpha * self.length_scale**2)\n",
    "            base = 1 + tmp\n",
    "            K = base**-self.alpha\n",
    "            np.fill_diagonal(K, 1)\n",
    "            print(\"No Y input\")\n",
    "        else:\n",
    "            if eval_gradient:\n",
    "                raise ValueError(\"Gradient can only be evaluated when Y is None.\")\n",
    "            dists = cdist(X, Y, metric=\"minkowski\",p=5)\n",
    "            K = (1 + dists / (2 * self.alpha * self.length_scale**2)) ** -self.alpha\n",
    "\n",
    "        if eval_gradient:\n",
    "            # gradient with respect to length_scale\n",
    "            if not self.hyperparameter_length_scale.fixed:\n",
    "                length_scale_gradient = dists * K / (self.length_scale**2 * base)\n",
    "                length_scale_gradient = length_scale_gradient[:, :, np.newaxis]\n",
    "            else:  # l is kept fixed\n",
    "                length_scale_gradient = np.empty((K.shape[0], K.shape[1], 0))\n",
    "\n",
    "            # gradient with respect to alpha\n",
    "            if not self.hyperparameter_alpha.fixed:\n",
    "                alpha_gradient = K * (\n",
    "                    -self.alpha * np.log(base)\n",
    "                    + dists / (2 * self.length_scale**2 * base)\n",
    "                )\n",
    "                alpha_gradient = alpha_gradient[:, :, np.newaxis]\n",
    "            else:  # alpha is kept fixed\n",
    "                alpha_gradient = np.empty((K.shape[0], K.shape[1], 0))\n",
    "\n",
    "            return K, np.dstack((alpha_gradient, length_scale_gradient))\n",
    "        else:\n",
    "            return K\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"{0}(alpha={1:.3g}, length_scale={2:.3g})\".format(\n",
    "            self.__class__.__name__, self.alpha, self.length_scale\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_laser_7mg=pd.read_excel(open(filepath, 'rb'), sheet_name='焦油含量7 mg的在线激光打孔参数组合表')\n",
    "df_laser_6mg=pd.read_excel(open(filepath, 'rb'), sheet_name='焦油含量6 mg的在线激光打孔参数组合表')\n",
    "df_sensory_6mg=pd.read_excel(open(filepath, 'rb'), sheet_name='焦油含量6 mg卷烟感官评价结果表')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.set_option(\"display.precision\",10)\n",
    "df=pd.DataFrame.from_dict(resultlist3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultlist4=[]\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "k=5\n",
    "kf=KFold(n_splits=k,shuffle=True, random_state=42)\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test=X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test=y.iloc[train_index],y.iloc[test_index]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVR with the grid search method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters={'C':np.arange(1,201,5),'gamma':np.arange(1e-7,1,0.1),'epsilon':np.arange(0.01,1,0.1)}\n",
    "\n",
    "resultslist4=[]\n",
    "\n",
    "def RationalQuadratic2(x,y,length_scale=2,alpha=1):\n",
    "    #length_scale = 2.0\n",
    "    #alpha = 1.0\n",
    "    dists = cdist(x, y, metric='sqeuclidean')\n",
    "    K = (1 + dists / (2 * alpha * length_scale ** 2)) ** - alpha\n",
    "    return K\n",
    "\n",
    "def RationalQuadratic_minkow_p(x,y,pp=5,length_scale=2,alpha=1):\n",
    "    #length_scale = 2.0\n",
    "    #alpha = 2.0\n",
    "    dists = cdist(x, y, metric='minkowski',p=pp)\n",
    "    K = (1 + dists / (2 * alpha * length_scale ** 2)) ** - alpha\n",
    "    return K\n",
    "\n",
    "def myrbf3(x,y,length_scale):\n",
    "    #length_scale=2\n",
    "    dists = cdist(x / length_scale, y / length_scale,  metric='sqeuclidean')\n",
    "    res = np.exp(-.5* dists)\n",
    "    return res\n",
    "\n",
    "svr_rbf = SVR(kernel='rbf',C=51, epsilon=0.1, gamma=0.5)\n",
    "svr_lin = SVR(kernel='linear',C=51, epsilon=0.1,gamma=1e-07)\n",
    "svr_rq=SVR(kernel=RationalQuadratic2,C=51, epsilon=0.1, gamma=1e-07)\n",
    "svr_rm= SVR(kernel=RationalQuadratic_minkow_p,C=151, epsilon=0.1, gamma=1e-07)\n",
    "\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.gaussian_process.kernels import DotProduct\n",
    "from sklearn.gaussian_process.kernels import RationalQuadratic\n",
    "\n",
    "kernel_lin=DotProduct()\n",
    "kernel_rm = RationalQuadratic_minkow_g(length_scale=2,alpha=1)  # new class for gaussian kernel has been defined in previous section\n",
    "kernel_rbf= RBF(length_scale=2)\n",
    "kernel_rq=RationalQuadratic(length_scale=2,alpha=1)  \n",
    "#kernel=RBF(length_scale=1.0)\n",
    "gp_lin = GaussianProcessRegressor(kernel=kernel_lin, normalize_y=True)\n",
    "gp_rq=GaussianProcessRegressor(kernel=kernel_rq, normalize_y=True)\n",
    "\n",
    "gp_rm = GaussianProcessRegressor(kernel=kernel_rm, normalize_y=True)\n",
    "gp_rbf=GaussianProcessRegressor(kernel=kernel_rbf, normalize_y=True)\n",
    "\n",
    "#svr_mahalanobis= SVR(kernel=mymahal,C=201, epsilon=0.01, gamma=1e-07)\n",
    "#svr_minkowski=SVR(kernel=myminkowski,C=201, epsilon=0.01, gamma=1e-07)\n",
    "\n",
    "# #############################################################################\n",
    "# Look at the results\n",
    "lw = 2\n",
    "\n",
    "#models = [svr_lin,svr_rbf,  svr_rq, svr_rm,gp_lin, gp_rbf,gp_rq,gp_rm]\n",
    "models = ['linear','rbf',RationalQuadratic2,RationalQuadratic_minkow_p,gp_lin, gp_rbf,gp_rq,gp_rm]\n",
    "#models = [RationalQuadratic2,RationalQuadratic_minkow_p]\n",
    "\n",
    "kernel_label = ['SVM Linear', 'SVM RBF','SVM RQ', 'SVM RM','GP Linear','GP RBF','GP RQ','GP RM']\n",
    "#kernel_label = ['SVM RQ', 'SVM RM']\n",
    "\n",
    "model_color = ['m', 'c', 'g','r','y','#00FFFF','#8FBC8F','#A0522D']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nrmse:0.1847286431230497 o1 rmse:0.6449792496625212  rs2:0.5840017675047711  rpd:1.5504374761253787\n",
      "out1:[0.7351815255691511, 1.1508341773039885, 0.7349474642923866, 1.1508341773039885, 0.4193925884916044, 0.21094778153299765, 0.5138140861412013, 0.27617987493090185, -0.0032131190298433088, 0.03854566372061492, 0.7514482973514913, 0.8348207776740627, 1.0686003929545398, 0.7514482973514913, 1.0680480216391142, 0.910533316508367, -0.5175985930710691, -0.5175985930710691, -0.27996438186076983, -0.8336119927009675, -1.073742849862755, -1.073742849862755, -0.27996438186076983, -0.2774677359092887, -0.8336119927009675, -0.13684447586745133, -1.6298871066544378, -1.3897562494926503, -0.8361086386524597, -1.6298871066544378, -1.3897562494926503, -0.6716562028531735]\n",
      "nrmse:0.08488125129823912 o1 rmse:0.2963625177297862  rs2:0.9121692580848622  rpd:3.3742458650313116\n",
      "out1:[1.677770467256571, 1.629697757583565, 1.9349805326337552, 1.7645347825758688, 0.6251403111426996, 0.7476648237862236, 0.6251255238738191, 0.7491030060139714, 0.512533114537316, 0.7075451940262083, 0.37532153821285386, -0.1160465212513726, 0.07010146595435751, 0.37467345267341656, 0.11997789145420779, 0.19081768754636919, 0.022686942470745652, 0.022037593134935474, -0.19033984779875768, -1.0015292910508053, -0.7925343130899991, -0.7924166786015983, -0.1904673236027974, -0.8183330194064533, -1.0010912713412692, -0.6870412863926485, -1.2766086292488699, -0.8890183032444416, -1.1080597786470614, -1.2357929850040739, -0.8885799170544182, -1.1080307704737433]\n",
      "nrmse:0.0974149151111754 o1 rmse:0.34012375012407786  rs2:0.8843158346015338  rpd:2.940106357274956\n",
      "out1:[1.8573421867548972, 1.3794713428421619, 1.8569357274659988, 1.4439932200753065, 0.8052794082249567, 0.7418347456377372, 0.9133552289398604, 0.8921309306373754, 0.4928086121414136, 0.4928086121414136, 0.41668738024560203, -0.43567168894100405, -0.22980268334076198, 0.5629333639483356, -0.18007092700571514, -0.10872793045768925, -0.21517282285070716, -0.21517282285070716, -0.22395524245523613, -0.9741495410419232, -0.914503040902963, -0.8864947254515801, -0.07626735734626654, -0.6772459026331316, -0.9064847729932272, -0.41532298487988356, -1.576667700617886, -1.146337713008101, -1.2360156180138833, -1.386592348796444, -0.8249465161237339, -0.9219931015114966]\n",
      "nrmse:0.07003686221104063 o1 rmse:0.24453339814500022  rs2:0.9402034171916588  rpd:4.0894209444839635\n",
      "out1:[1.55813894987524, 1.5090107114017222, 1.8351904314105076, 1.6444304487114176, 0.9977633747830706, 0.846068304839764, 0.9974764970910108, 1.0920129002302588, 0.612494970860549, 0.7363653352590119, 0.21636415274701515, -0.016046485201358707, 0.15258316391263949, 0.3629952009338303, 0.15258316391263949, 0.0905558043997538, -0.0864261954676081, -0.06283034973514978, -0.5282892298663242, -0.9454468849644322, -0.7484236528676589, -0.6857976314063737, -0.27629279149213176, -0.8775174667653884, -0.6086712455275591, -0.587043413773584, -1.1572765096085207, -1.3465176774022936, -1.4357826443493111, -1.0971646478206927, -1.0171264469940446, -1.1043824189455937]\n",
      "nrmse:0.19056022743847228 o1 rmse:0.6653402007988297  rs2:0.557322417200973  rpd:1.5029904983937035\n",
      "out1:[0.7784387269046494, 1.0626079234221086, 0.7982749545915446, 1.0803678386286044, 0.5257843334495642, 0.3087847991310726, 0.5330220793550848, 0.3230680342584069, 0.09499355812005496, 0.10473431888748513, 0.8584339302357576, 0.9995058315227254, 1.1944688388379743, 0.8753486085923803, 1.2041350426435846, 1.0844319056759673, -0.4038796937112894, -0.4029288249762146, -0.15902086362276963, -0.7248972569798976, -0.9353687924920094, -0.9301116474929904, -0.14755459532092424, -0.13374848471883266, -0.6891366367931182, -0.10118340113091612, -1.4797941873427285, -1.2282539078528267, -0.6351986079322925, -1.4467135890028566, -1.181873573420577, -0.6064332288869254]\n",
      "nrmse:0.07022629439534521 o1 rmse:0.2451947997881299  rs2:0.9398795101568589  rpd:4.078389920439132\n",
      "out1:[1.6681128620092411, 1.619514359422854, 1.9453872845856761, 1.7544263347913156, 1.1157066362130212, 0.8513853215415015, 1.2238115217275427, 1.2020201089952471, 0.5022357588686871, 0.787715439647463, 0.10653292117304067, -0.12623345394289517, 0.07994496284427542, 0.25257190840639554, 0.12980955868520672, 0.2007838247385341, -0.19625815005402183, -0.17278672896483377, -0.6383194791964243, -0.8349778486325412, -0.6383194791958117, -0.5760374302890213, -0.38614779017077006, -0.9874690418695748, -0.49865965412531665, -0.6968762921813271, -1.2667886920076696, -1.4564348526538784, -1.5461083421465458, -1.0766555724169269, -1.1271288669367852, -1.214757128865663]\n",
      "nrmse:0.0702263048923163 o1 rmse:0.24519483643825854  rs2:0.9398794921840157  rpd:4.078389310827945\n",
      "out1:[1.6681143447463287, 1.619513011582662, 1.9453876506867918, 1.754427452626168, 1.1157068324864945, 0.8513862970005726, 1.223811536624533, 1.2020195433813299, 0.5022350310477494, 0.7877158961316361, 0.10653388683802684, -0.12623353546864588, 0.07994558675158686, 0.252571637642072, 0.12980955067322672, 0.200784225806203, -0.1962583298129269, -0.17278631900225672, -0.6383194348536817, -0.8349773948676155, -0.6383192234139988, -0.576038345988955, -0.3861481168482798, -0.9874693346304466, -0.49865933341113156, -0.6968764444838415, -1.266789710884722, -1.456434971571585, -1.5461087466829775, -1.076654878634784, -1.1271286339287934, -1.2147567615917796]\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "No Y input\n",
      "nrmse:0.07022632433858525 o1 rmse:0.24519490433482158  rs2:0.9398794588882377  rpd:4.078388181487114\n",
      "out1:[1.6681137624248348, 1.6195131786815562, 1.9453872845856761, 1.7544267423154525, 1.1157069809158646, 0.8513845114286295, 1.2238103079928913, 1.2020201089952471, 0.5022357588686871, 0.7877169854683526, 0.10653304435011635, -0.12623380656366978, 0.07994374552105582, 0.25257222508763727, 0.1298096899445288, 0.20078382473853412, -0.1962583355239407, -0.17278672896483377, -0.6383204025064453, -0.8349782350976337, -0.6383194791958117, -0.5760379081476187, -0.38614736253018866, -0.9874690004089133, -0.49865955459563116, -0.6968759031862342, -1.2667886920076696, -1.4564348706237167, -1.5461083370182023, -1.0766555724169269, -1.1271288669367852, -1.2147586255897047]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#fig, axes = plt.subplots(nrows=4, ncols=2, figsize=(12, 12), sharey=True)\n",
    "for ix, model in enumerate(models):\n",
    "        #model=svr.fit(X,y)\n",
    "        #rn=range(len(y))\n",
    "        #model.decision_function(X.ravel()) \n",
    "\n",
    "        out1=[]\n",
    "        start=time.time()\n",
    "        if 'SVM' in kernel_label[ix]:\n",
    "            modeltmp= SVR(kernel=model)\n",
    "            grid_search=GridSearchCV(modeltmp,parameters,cv=5)\n",
    "            grid_search.fit(X,y)\n",
    "            bestmodel=SVR(kernel=model,**grid_search.best_params_)\n",
    "            model=bestmodel\n",
    "        for i in range(0,df_laser_tar.shape[0]):\n",
    "                gx=np.delete(X,i,0)\n",
    "                gy=np.delete(y,i,0)\n",
    "                testx = X[i,:].reshape(1,2)             \n",
    "                o1 = model.fit(gx,gy.flatten()).predict(testx)\n",
    "                out1.append(o1[0])\n",
    "        end=time.time()\n",
    "        mso1=mean_squared_error(y,np.array(out1).reshape(-1,1),squared=False)\n",
    "        nrmse1=nrmse(y,mso1)\n",
    "        rso1=r2_score(y,np.array(out1).reshape(-1,1))\n",
    "        rpd1=rpdd(y,np.array(out1).reshape(-1,1))\n",
    "        print('nrmse:'+str(nrmse1)+' o1 rmse:'+str(mso1)+'  rs2:'+str(rso1 )+'  rpd:'+str(rpd1))\n",
    "        print('out1:'+str(out1))\n",
    "        dd=dict(kernelname=kernel_label[ix],nrmse=nrmse1,rmse=mso1,r2=rso1,rpd=rpd1,time=(end-start),params=grid_search.best_params_)\n",
    "        resultslist4.append(dd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 16, 'epsilon': 0.11, 'gamma': 1e-07}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kernelname</th>\n",
       "      <th>nrmse</th>\n",
       "      <th>rmse</th>\n",
       "      <th>r2</th>\n",
       "      <th>rpd</th>\n",
       "      <th>time</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM Linear</td>\n",
       "      <td>0.1847286431</td>\n",
       "      <td>0.6449792497</td>\n",
       "      <td>0.5840017675</td>\n",
       "      <td>1.5504374761</td>\n",
       "      <td>65.8655939102</td>\n",
       "      <td>{'C': 11, 'epsilon': 0.7100000000000001, 'gamm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVM RBF</td>\n",
       "      <td>0.0848812513</td>\n",
       "      <td>0.2963625177</td>\n",
       "      <td>0.9121692581</td>\n",
       "      <td>3.3742458650</td>\n",
       "      <td>28.0556702614</td>\n",
       "      <td>{'C': 91, 'epsilon': 0.01, 'gamma': 0.10000010...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVM RQ</td>\n",
       "      <td>0.0974149151</td>\n",
       "      <td>0.3401237501</td>\n",
       "      <td>0.8843158346</td>\n",
       "      <td>2.9401063573</td>\n",
       "      <td>25.2676975727</td>\n",
       "      <td>{'C': 96, 'epsilon': 0.31000000000000005, 'gam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVM RM</td>\n",
       "      <td>0.0700368622</td>\n",
       "      <td>0.2445333981</td>\n",
       "      <td>0.9402034172</td>\n",
       "      <td>4.0894209445</td>\n",
       "      <td>24.9611752033</td>\n",
       "      <td>{'C': 16, 'epsilon': 0.11, 'gamma': 1e-07}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GP Linear</td>\n",
       "      <td>0.1905602274</td>\n",
       "      <td>0.6653402008</td>\n",
       "      <td>0.5573224172</td>\n",
       "      <td>1.5029904984</td>\n",
       "      <td>0.2092382908</td>\n",
       "      <td>{'C': 16, 'epsilon': 0.11, 'gamma': 1e-07}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GP RBF</td>\n",
       "      <td>0.0702262944</td>\n",
       "      <td>0.2451947998</td>\n",
       "      <td>0.9398795102</td>\n",
       "      <td>4.0783899204</td>\n",
       "      <td>0.0853378773</td>\n",
       "      <td>{'C': 16, 'epsilon': 0.11, 'gamma': 1e-07}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GP RQ</td>\n",
       "      <td>0.0702263049</td>\n",
       "      <td>0.2451948364</td>\n",
       "      <td>0.9398794922</td>\n",
       "      <td>4.0783893108</td>\n",
       "      <td>0.7057085037</td>\n",
       "      <td>{'C': 16, 'epsilon': 0.11, 'gamma': 1e-07}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>GP RM</td>\n",
       "      <td>0.0702263243</td>\n",
       "      <td>0.2451949043</td>\n",
       "      <td>0.9398794589</td>\n",
       "      <td>4.0783881815</td>\n",
       "      <td>0.6127557755</td>\n",
       "      <td>{'C': 16, 'epsilon': 0.11, 'gamma': 1e-07}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   kernelname         nrmse          rmse            r2           rpd  \\\n",
       "0  SVM Linear  0.1847286431  0.6449792497  0.5840017675  1.5504374761   \n",
       "1     SVM RBF  0.0848812513  0.2963625177  0.9121692581  3.3742458650   \n",
       "2      SVM RQ  0.0974149151  0.3401237501  0.8843158346  2.9401063573   \n",
       "3      SVM RM  0.0700368622  0.2445333981  0.9402034172  4.0894209445   \n",
       "4   GP Linear  0.1905602274  0.6653402008  0.5573224172  1.5029904984   \n",
       "5      GP RBF  0.0702262944  0.2451947998  0.9398795102  4.0783899204   \n",
       "6       GP RQ  0.0702263049  0.2451948364  0.9398794922  4.0783893108   \n",
       "7       GP RM  0.0702263243  0.2451949043  0.9398794589  4.0783881815   \n",
       "\n",
       "            time                                             params  \n",
       "0  65.8655939102  {'C': 11, 'epsilon': 0.7100000000000001, 'gamm...  \n",
       "1  28.0556702614  {'C': 91, 'epsilon': 0.01, 'gamma': 0.10000010...  \n",
       "2  25.2676975727  {'C': 96, 'epsilon': 0.31000000000000005, 'gam...  \n",
       "3  24.9611752033         {'C': 16, 'epsilon': 0.11, 'gamma': 1e-07}  \n",
       "4   0.2092382908         {'C': 16, 'epsilon': 0.11, 'gamma': 1e-07}  \n",
       "5   0.0853378773         {'C': 16, 'epsilon': 0.11, 'gamma': 1e-07}  \n",
       "6   0.7057085037         {'C': 16, 'epsilon': 0.11, 'gamma': 1e-07}  \n",
       "7   0.6127557755         {'C': 16, 'epsilon': 0.11, 'gamma': 1e-07}  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.set_option(\"display.precision\",10)\n",
    "df=pd.DataFrame.from_dict(resultslist4)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill\n",
    "\n",
    "dill.dump_session('svr_with_search_grid4.pkl')  # Save the entire session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVR with the L-BFGS-B method, not work well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.svm import SVR\n",
    "from scipy.optimize import fmin_l_bfgs_b\n",
    "\n",
    "def objective(params):\n",
    "    C, epsilon, gamma = params\n",
    "    svr = SVR(C=C, epsilon=epsilon, gamma=gamma)\n",
    "    svr.fit(X_train, y_train)\n",
    "    y_pred = svr.predict(X_val)\n",
    "    mse = mean_squared_error(y_val, y_pred)\n",
    "    return mse\n",
    "\n",
    "from scipy.optimize import fmin_l_bfgs_b\n",
    "\n",
    "initial_guess = [1.0, 0.1, 0.1]  # Initial values for C, epsilon, and gamma\n",
    "bounds = [(1e-3, 1e2), (1e-3, 1.0), (1e-3, 10)]  # Bounds for C, epsilon, and gamma\n",
    "\n",
    "result = fmin_l_bfgs_b(objective, initial_guess, bounds=bounds)\n",
    "best_C, best_epsilon, best_gamma = result[0]\n",
    "\n",
    "best_svr = SVR(C=best_C, epsilon=best_epsilon, gamma=best_gamma)\n",
    "best_svr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.optimize import fmin_l_bfgs_b\n",
    "\n",
    "def objective(params,kernelt):\n",
    "    C, epsilon, gamma = params\n",
    "    svr = SVR(kernel=kernelt, C=C, epsilon=epsilon, gamma=gamma)\n",
    "    svr.fit(X_train, y_train)\n",
    "    y_pred = svr.predict(X_val)\n",
    "    mse = mean_squared_error(y_val, y_pred)\n",
    "    return mse\n",
    "\n",
    "lw = 2\n",
    "from scipy.optimize import fmin_l_bfgs_b\n",
    "\n",
    "initial_guess = [1.0, 0.1, 0.1]  # Initial values for C, epsilon, and gamma\n",
    "bounds = [(1e-3, 1e2), (1e-3, 1.0), (1e-3, 10)]  # Bounds for C, epsilon, and gamma\n",
    "\n",
    "models = ['linear','rbf',RationalQuadratic2,RationalQuadratic_minkow_p,gp_lin, gp_rbf,gp_rq,gp_rm]\n",
    "kernel_label = ['SVM Linear', 'SVM RBF','SVM RQ', 'SVM RM','GP Linear','GP RBF','GP RQ','GP RM']\n",
    "model_color = ['m', 'c', 'g','r','y','#00FFFF','#8FBC8F','#A0522D']\n",
    "\n",
    "#svr_rbf = SVR(kernel='rbf',C=51, epsilon=0.1, gamma=0.5)\n",
    "#svr_lin = SVR(kernel='linear',C=51, epsilon=0.1,gamma=1e-07)\n",
    "#svr_rq=SVR(kernel=RationalQuadratic2,C=51, epsilon=0.1, gamma=1e-07)\n",
    "#svr_rm= SVR(kernel=RationalQuadratic_minkow_p,C=151, epsilon=0.1, gamma=1e-07)\n",
    "#fig, axes = plt.subplots(nrows=4, ncols=2, figsize=(12, 12), sharey=True)\n",
    "for ix, model in enumerate(models):\n",
    "        #model=svr.fit(X,y)\n",
    "        #rn=range(len(y))\n",
    "        #model.decision_function(X.ravel()) \n",
    "\n",
    "        out1=[]\n",
    "        start=time.time()\n",
    "        if 'SVM' in kernel_label[ix]:\n",
    "            result = fmin_l_bfgs_b(objective(kernelt=model), initial_guess, bounds=bounds)\n",
    "            best_C, best_epsilon, best_gamma = result[0]\n",
    "            bestmodel=SVR(kernel=model,C=best_C, epsilon=best_epsilon, gamma=best_gamma)\n",
    "            modelt=bestmodel\n",
    "        else:\n",
    "            modelt=model   \n",
    "        for i in range(0,df_laser_tar.shape[0]):\n",
    "                gx=np.delete(X,i,0)\n",
    "                gy=np.delete(y,i,0)\n",
    "                testx = X[i,:].reshape(1,2)             \n",
    "                o1 = modelt.fit(gx,gy.flatten()).predict(testx)\n",
    "                out1.append(o1[0])\n",
    "        end=time.time()\n",
    "        mso1=mean_squared_error(y,np.array(out1).reshape(-1,1),squared=False)\n",
    "        nrmse1=nrmse(y,mso1)\n",
    "        rso1=r2_score(y,np.array(out1).reshape(-1,1))\n",
    "        rpd1=rpdd(y,np.array(out1).reshape(-1,1))\n",
    "        print('nrmse:'+str(nrmse1)+' o1 rmse:'+str(mso1)+'  rs2:'+str(rso1 )+'  rpd:'+str(rpd1))\n",
    "        print('out1:'+str(out1))\n",
    "        dd=dict(kernelname=kernel_label[ix],nrmse=nrmse1,rmse=mso1,r2=rso1,rpd=rpd1,time=(end-start))\n",
    "        resultslist4.append(dd)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
